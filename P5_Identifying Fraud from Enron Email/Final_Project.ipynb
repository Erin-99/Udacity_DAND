{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "sys.path.append(\"../tools/\")\n",
    "\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "data_dict.pop('TOTAL')\n",
    "data_dict.pop('THE TRAVEL AGENCY IN THE PARK') # Not a name\n",
    "data_dict.pop('LOCKHART EUGENE E') # All data is NaN\n",
    "my_dataset = data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute fraction\n",
    "def computeFraction( poi_messages, all_messages ):\n",
    "    \"\"\" given a number messages to/from POI (numerator) \n",
    "        and number of all messages to/from a person (denominator),\n",
    "        return the fraction of messages to/from that person\n",
    "        that are from/to a POI\n",
    "   \"\"\"\n",
    "\n",
    "\n",
    "    ### you fill in this code, so that it returns either\n",
    "    ###     the fraction of all messages to this person that come from POIs\n",
    "    ###     or\n",
    "    ###     the fraction of all messages from this person that are sent to POIs\n",
    "    ### the same code can be used to compute either quantity\n",
    "\n",
    "    ### beware of \"NaN\" when there is no known email address (and so\n",
    "    ### no filled email features), and integer division!\n",
    "    ### in case of poi_messages or all_messages having \"NaN\" value, return 0.\n",
    "    if poi_messages == 'NaN' or all_messages == 'NaN':\n",
    "        fraction = 0\n",
    "    else:\n",
    "        fraction = poi_messages *1.0 / all_messages\n",
    "\n",
    "\n",
    "\n",
    "    return fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add the new features to dataset\n",
    "for name in my_dataset:\n",
    "    data_point = my_dataset[name]\n",
    "    from_poi_to_this_person = data_point[\"from_poi_to_this_person\"]\n",
    "    to_messages = data_point[\"to_messages\"]\n",
    "    fraction_from_poi = computeFraction( from_poi_to_this_person, to_messages )\n",
    "    data_point[\"fraction_from_poi\"] = fraction_from_poi\n",
    "    \n",
    "    from_this_person_to_poi = data_point[\"from_this_person_to_poi\"]\n",
    "    from_messages = data_point[\"from_messages\"]\n",
    "    fraction_to_poi = computeFraction( from_this_person_to_poi, from_messages )\n",
    "\n",
    "    data_point[\"fraction_to_poi\"] = fraction_to_poi\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of people: 143\n"
     ]
    }
   ],
   "source": [
    "print 'Total # of people:',len(my_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of features: 23\n"
     ]
    }
   ],
   "source": [
    "print 'Total # of features:',len(my_dataset[my_dataset.keys()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poi:  18\n",
      "non-poi:  125\n"
     ]
    }
   ],
   "source": [
    "# poi and non-poi\n",
    "positive=0\n",
    "negative=0\n",
    "for name in my_dataset:\n",
    "    if my_dataset[name]['poi']==True:\n",
    "        positive+=1\n",
    "    elif my_dataset[name]['poi']==False:\n",
    "        negative+=1\n",
    "\n",
    "print 'poi: ',positive\n",
    "print 'non-poi: ',negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {'salary': 49, 'to_messages': 57, 'deferral_payments': 105, 'total_payments': 20, 'exercised_stock_options': 42, 'bonus': 62, 'restricted_stock': 34, 'restricted_stock_deferred': 126, 'total_stock_value': 18, 'director_fees': 127, 'from_poi_to_this_person': 57, 'loan_advances': 140, 'from_messages': 57, 'other': 52, 'expenses': 49, 'from_this_person_to_poi': 57, 'deferred_income': 95, 'shared_receipt_with_poi': 57, 'email_address': 32, 'long_term_incentive': 78})\n"
     ]
    }
   ],
   "source": [
    "# compute nan values\n",
    "from collections import defaultdict\n",
    "na_count=defaultdict(int)\n",
    "for name in my_dataset:\n",
    "    for feature in my_dataset[name]:\n",
    "        if my_dataset[name][feature]=='NaN':\n",
    "            na_count[feature]+=1\n",
    "print na_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tester.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "\n",
    "PERF_FORMAT_STRING = \"\\\n",
    "\\tAccuracy: {:>0.{display_precision}f}\\tPrecision: {:>0.{display_precision}f}\\t\\\n",
    "Recall: {:>0.{display_precision}f}\\tF1: {:>0.{display_precision}f}\\tF2: {:>0.{display_precision}f}\"\n",
    "RESULTS_FORMAT_STRING = \"\\tTotal predictions: {:4d}\\tTrue positives: {:4d}\\tFalse positives: {:4d}\\\n",
    "\\tFalse negatives: {:4d}\\tTrue negatives: {:4d}\"\n",
    "\n",
    "def test_classifier(clf, dataset, feature_list, folds = 1000):\n",
    "    data = featureFormat(dataset, feature_list, sort_keys = True)\n",
    "    labels, features = targetFeatureSplit(data)\n",
    "    cv = StratifiedShuffleSplit(labels, folds, random_state = 42)\n",
    "    true_negatives = 0\n",
    "    false_negatives = 0\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    for train_idx, test_idx in cv: \n",
    "        features_train = []\n",
    "        features_test  = []\n",
    "        labels_train   = []\n",
    "        labels_test    = []\n",
    "        for ii in train_idx:\n",
    "            features_train.append( features[ii] )\n",
    "            labels_train.append( labels[ii] )\n",
    "        for jj in test_idx:\n",
    "            features_test.append( features[jj] )\n",
    "            labels_test.append( labels[jj] )\n",
    "        \n",
    "        ### fit the classifier using training set, and test on test set\n",
    "        clf.fit(features_train, labels_train)\n",
    "        predictions = clf.predict(features_test)\n",
    "        for prediction, truth in zip(predictions, labels_test):\n",
    "            if prediction == 0 and truth == 0:\n",
    "                true_negatives += 1\n",
    "            elif prediction == 0 and truth == 1:\n",
    "                false_negatives += 1\n",
    "            elif prediction == 1 and truth == 0:\n",
    "                false_positives += 1\n",
    "            elif prediction == 1 and truth == 1:\n",
    "                true_positives += 1\n",
    "            else:\n",
    "                print \"Warning: Found a predicted label not == 0 or 1.\"\n",
    "                print \"All predictions should take value 0 or 1.\"\n",
    "                print \"Evaluating performance for processed predictions:\"\n",
    "                break\n",
    "    try:\n",
    "        total_predictions = true_negatives + false_negatives + false_positives + true_positives\n",
    "        accuracy = 1.0*(true_positives + true_negatives)/total_predictions\n",
    "        precision = 1.0*true_positives/(true_positives+false_positives)\n",
    "        recall = 1.0*true_positives/(true_positives+false_negatives)\n",
    "        f1 = 2.0 * true_positives/(2*true_positives + false_positives+false_negatives)\n",
    "        f2 = (1+2.0*2.0) * precision*recall/(4*precision + recall)\n",
    "        print clf\n",
    "        print PERF_FORMAT_STRING.format(accuracy, precision, recall, f1, f2, display_precision = 5)\n",
    "        print RESULTS_FORMAT_STRING.format(total_predictions, true_positives, false_positives, false_negatives, true_negatives)\n",
    "        print \"\"\n",
    "    except:\n",
    "        print \"Got a divide by zero when trying out:\", clf\n",
    "        print \"Precision or recall may be undefined due to a lack of true positive predicitons.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier for all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "features_list = ['poi','salary',  'deferral_payments', 'total_payments', 'loan_advances', 'bonus', 'restricted_stock_deferred', 'deferred_income', 'total_stock_value', 'expenses', 'exercised_stock_options', 'other', 'long_term_incentive', 'restricted_stock', 'director_fees','to_messages',  'from_poi_to_this_person', 'from_messages', 'from_this_person_to_poi', 'shared_receipt_with_poi','fraction_from_poi','fraction_to_poi']\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[2,3,4,5,6,7,8],\n",
    "          'min_samples_split': [2,5,8,10,12,15,20],\n",
    "          'min_samples_leaf':[1,2,5,8,10],\n",
    "          }\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "clf_grid = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid,cv=cv,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting done in 84.134s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0=time()\n",
    "clf_grid.fit(features,labels)\n",
    "print \"Fitting done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=15, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.82893\tPrecision: 0.34119\tRecall: 0.30400\tF1: 0.32152\tF2: 0.31077\n",
      "\tTotal predictions: 15000\tTrue positives:  608\tFalse positives: 1174\tFalse negatives: 1392\tTrue negatives: 11826\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.08330184,  0.17014983,  0.40804035,\n",
       "        0.        ,  0.        ,  0.04565957,  0.        ,  0.        ,\n",
       "        0.        ,  0.11832326,  0.        ,  0.        ,  0.        ,\n",
       "        0.17452516])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Best estimator found by grid search:\"\n",
    "print clf_grid.best_estimator_\n",
    "clf=clf_grid.best_estimator_\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree for the important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi', 'total_stock_value', 'expenses', 'exercised_stock_options', 'restricted_stock',  'from_messages','fraction_to_poi']\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[2,3,4,5,6,7,8],\n",
    "          'min_samples_split': [2,5,8,10,12,15,20],\n",
    "          'min_samples_leaf':[1,2,5,8,10],\n",
    "          }\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "clf_grid = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid,cv=cv,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting done in 73.858s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0=time()\n",
    "clf_grid.fit(features,labels)\n",
    "print \"Fitting done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=8,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=8,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.83800\tPrecision: 0.44398\tRecall: 0.53100\tF1: 0.48361\tF2: 0.51097\n",
      "\tTotal predictions: 14000\tTrue positives: 1062\tFalse positives: 1330\tFalse negatives:  938\tTrue negatives: 10670\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.41964445,  0.07851991,  0.        ,  0.        ,\n",
       "        0.50183564])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Best estimator found by grid search:\"\n",
    "print clf_grid.best_estimator_\n",
    "clf=clf_grid.best_estimator_\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree for the important features except for the new created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi', 'expenses', 'exercised_stock_options','fraction_to_poi']\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[2,3,4,5,6,7,8],\n",
    "          'min_samples_split': [2,5,8,10,12,15,20],\n",
    "          'min_samples_leaf':[1,2,5,8,10],\n",
    "          }\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "clf_grid = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid,cv=cv,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting done in 76.130s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0=time()\n",
    "clf_grid.fit(features,labels)\n",
    "print \"Fitting done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=8,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=8,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.83057\tPrecision: 0.42536\tRecall: 0.53000\tF1: 0.47195\tF2: 0.50515\n",
      "\tTotal predictions: 14000\tTrue positives: 1060\tFalse positives: 1432\tFalse negatives:  940\tTrue negatives: 10568\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.49230607,  0.        ,  0.50769393])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Best estimator found by grid search:\"\n",
    "print clf_grid.best_estimator_\n",
    "clf=clf_grid.best_estimator_\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "features_list = ['poi', 'total_stock_value', 'expenses', 'exercised_stock_options', 'restricted_stock',  'from_messages','fraction_to_poi']\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "features = MinMaxScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[2,3,4,5,6,7,8],\n",
    "          'min_samples_split': [2,5,8,10,12,15,20],\n",
    "          'min_samples_leaf':[1,2,5,8,10],\n",
    "          }\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "clf_grid = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid,cv=cv,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting done in 67.031s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0=time()\n",
    "clf_grid.fit(features,labels)\n",
    "print \"Fitting done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=8,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=8,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.83793\tPrecision: 0.44389\tRecall: 0.53200\tF1: 0.48397\tF2: 0.51169\n",
      "\tTotal predictions: 14000\tTrue positives: 1064\tFalse positives: 1333\tFalse negatives:  936\tTrue negatives: 10667\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.41964445,  0.07851991,  0.        ,  0.        ,\n",
       "        0.50183564])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Best estimator found by grid search:\"\n",
    "print clf_grid.best_estimator_\n",
    "clf=clf_grid.best_estimator_\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree for the important features except for the new created features with MinMax Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi', 'total_stock_value', 'expenses', 'exercised_stock_options', 'restricted_stock',  'from_messages']\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "features = MinMaxScaler().fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':[2,3,4,5,6,7,8],\n",
    "          'min_samples_split': [2,5,8,10,12,15,20],\n",
    "          'min_samples_leaf':[1,2,5,8,10],\n",
    "          }\n",
    "cv = StratifiedShuffleSplit(labels, 100, random_state = 42)\n",
    "\n",
    "clf_grid = GridSearchCV(DecisionTreeClassifier(), param_grid=param_grid,cv=cv,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting done in 77.731s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0=time()\n",
    "clf_grid.fit(features,labels)\n",
    "print \"Fitting done in %0.3fs\" % (time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator found by grid search:\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=8,\n",
      "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n",
      "\tAccuracy: 0.80250\tPrecision: 0.30554\tRecall: 0.30050\tF1: 0.30300\tF2: 0.30149\n",
      "\tTotal predictions: 14000\tTrue positives:  601\tFalse positives: 1366\tFalse negatives: 1399\tTrue negatives: 10634\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.22307666,  0.33850749,  0.15116764,  0.25436905,  0.03287917])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"Best estimator found by grid search:\"\n",
    "print clf_grid.best_estimator_\n",
    "clf=clf_grid.best_estimator_\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)\n",
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## naive_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n",
      "GaussianNB()\n",
      "\tAccuracy: 0.84757\tPrecision: 0.44472\tRecall: 0.26950\tF1: 0.33562\tF2: 0.29255\n",
      "\tTotal predictions: 14000\tTrue positives:  539\tFalse positives:  673\tFalse negatives: 1461\tTrue negatives: 11327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from email_preprocess import preprocess\n",
    "features_list = ['poi', 'total_stock_value', 'expenses', 'exercised_stock_options', 'restricted_stock',  'from_messages','fraction_to_poi']\n",
    "data = featureFormat(my_dataset, features_list, sort_keys = True)\n",
    "labels, features = targetFeatureSplit(data)\n",
    "features = MinMaxScaler().fit_transform(features)\n",
    "clf = GaussianNB()\n",
    "features_train, features_test, labels_train, labels_test = preprocess()\n",
    "clf.fit(features_train,labels_train)\n",
    "test_classifier(clf, my_dataset, features_list, folds = 1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
